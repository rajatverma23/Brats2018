{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1708009,"sourceType":"datasetVersion","datasetId":958228}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install pyradiomics\n! pip install torch-summary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing libararies\nimport cv2\nimport os\nimport pdb\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\nfrom torchsummary import summary\n\nimport nibabel as nib\nimport scipy.ndimage as ndi\nfrom sklearn.preprocessing import LabelBinarizer\n\nimport radiomics\nfrom radiomics import featureextractor\nimport SimpleITK as sitk\nimport six\nfrom sklearn.preprocessing import StandardScaler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Paths","metadata":{}},{"cell_type":"code","source":"# train data\ndirectory_path_train = '/kaggle/input/brats2018/MICCAI_BraTS_2018_Data_Training'\nhigh_grade_glioma_train = '/kaggle/input/brats2018/MICCAI_BraTS_2018_Data_Training/HGG'\nlow_grade_glioma_train = '/kaggle/input/brats2018/MICCAI_BraTS_2018_Data_Training/LGG'\nsurvival_csv_train = '/kaggle/input/brats2018/MICCAI_BraTS_2018_Data_Training/survival_data.csv'\n# val data\ndirectory_path_val = '/kaggle/input/brats2018/MICCAI_BraTS_2018_Data_Validation'\nsurvival_csv_val = '/kaggle/input/brats2018/MICCAI_BraTS_2018_Data_Validation/survival_evaluation.csv'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handling the csv file","metadata":{}},{"cell_type":"markdown","source":"### Encoding scheme of resection status\n#### NaN : [0, 0]\n#### STR : [0, 1]\n#### GTR : [1, 0]","metadata":{}},{"cell_type":"code","source":"resection_status = { 'nan' : [0, 0], 'STR': [0, 1], 'GTR': [1, 0]} ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reading the data from CSV file\ntrain_survival = pd.read_csv(survival_csv_train)\ntrain_survival_dict = train_survival.set_index('BraTS18ID').T.to_dict('list')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Function for feautre vector of a segmented MRI","metadata":{}},{"cell_type":"code","source":"def vol_and_SA(extractor, image, mask):\n    feautres = extractor.execute(image, mask) \n    MeshVolume = 0\n    SurfaceArea = 0\n    for key, value in feautres.items():\n        if key == 'original_shape_MeshVolume':\n            MeshVolume = value\n        elif key == 'original_shape_SurfaceArea':\n            SurfaceArea = value\n            \n    return MeshVolume, SurfaceArea","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_mask(seg_mri, masked_val):\n    mask = np.zeros_like(seg_mri)\n    for slice in range(0, seg_mri.shape[0]):\n        for row in range(0, seg_mri.shape[1]):\n            for col in range(0, seg_mri.shape[2]):\n                if seg_mri[slice][row][col] == masked_val:\n                    mask[slice][row][col] = 1\n    \n    return mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_feautre_vector(seg_mri):\n    feautre_vector = []\n    \n    necrotic_net_mask = get_mask(seg_mri, masked_val = 1) # 0 - background, 1 - necrotic and non_enhancing tumor\n    peritumoral_edema_mask = get_mask(seg_mri, masked_val = 2) # 0 - background, 1 - peritumoral edema\n    enhancing_tumor_mask = get_mask(seg_mri, masked_val = 4) # 0 - background, 1 - enhancing tumor\n    \n    seg_image = sitk.GetImageFromArray(seg_mri)\n    necrotic_net_mask_image = sitk.GetImageFromArray(necrotic_net_mask)\n    peritumoral_edema_mask_image = sitk.GetImageFromArray(peritumoral_edema_mask)\n    enhancing_tumor_mask_image = sitk.GetImageFromArray(enhancing_tumor_mask)\n    \n    extractor = featureextractor.RadiomicsFeatureExtractor()\n    MeshVolume_necrotic_net, SurfaceArea_necrotic_net = vol_and_SA(extractor, seg_image, necrotic_net_mask_image)\n    MeshVolume_peritumoral_edema, SurfaceArea_peritumoral_edema = vol_and_SA(extractor, seg_image, peritumoral_edema_mask_image)\n    MeshVolume_enhancing_tumor, SurfaceArea_enhancing_tumor = vol_and_SA(extractor, seg_image, enhancing_tumor_mask_image)\n#     print(type(MeshVolume_necrotic_net))\n    feautre_vector.append(float(MeshVolume_necrotic_net))\n    feautre_vector.append(float(SurfaceArea_necrotic_net))\n    feautre_vector.append(float(MeshVolume_peritumoral_edema))\n    feautre_vector.append(float(SurfaceArea_peritumoral_edema))\n    feautre_vector.append(float(MeshVolume_enhancing_tumor))\n    feautre_vector.append(float(SurfaceArea_enhancing_tumor))\n    \n    return feautre_vector","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get feautre vector for regressor model","metadata":{}},{"cell_type":"code","source":"def get_input_GT_data(dir_path):\n    input_data = []\n    gt = []\n    i = 0\n    main_files = os.listdir(dir_path)\n    for main_file in main_files:\n        full_main_path = os.path.join(dir_path, main_file)\n        try : \n            files = os.listdir(full_main_path)\n        except NotADirectoryError : \n            continue\n        for file in files:\n            full_dir_path = os.path.join(full_main_path, file)\n            vimage_files = os.listdir(full_dir_path)\n#             print(file)\n            try : \n                age, survival, resection = train_survival_dict[file]\n                resection_str = str(resection)\n            except KeyError :\n                continue\n            for vimage_file in vimage_files:\n                if \"seg\" in vimage_file:\n                    vimage_path = os.path.join(full_dir_path, vimage_file)\n                    print(vimage_file)                      \n                    brain_vol = nib.load(vimage_path)\n                    brain_vol_data = brain_vol.get_fdata()\n                    feautre_vector = get_feautre_vector(brain_vol_data)\n                    feautre_vector.append(age)\n                    print(resection_str)\n                    feautre_vector.append(resection_status[resection_str][0])\n                    feautre_vector.append(resection_status[resection_str][1])\n                    feautre_vector.append(file)\n                    feautre_vector.append(survival)\n                    input_data.append(feautre_vector)\n                    gt.append(survival)\n            if i == 20:\n                break\n            i = i + 1\n    return (input_data, gt)\n\n# reading the MRI train images\n(input_data, gt) = get_input_GT_data(directory_path_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Saving the feautres to csv file ","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(input_data).to_csv('data_input_and_labels3.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reshaping\ninput_d = []\nfor i in range(21):\n    input_d.append(input_data[i][0 : -2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualise a MRI","metadata":{}},{"cell_type":"code","source":"# visualise each slice\ndef visualise_each_slice(brain_vol_data):\n    fig_rows = 4\n    fig_cols = 4\n    n_subplots = fig_rows * fig_cols\n    n_slice = brain_vol_data.shape[0]\n    step_size = n_slice // n_subplots\n    plot_range = n_subplots * step_size\n    start_stop = int((n_slice - plot_range) / 2)\n    fig, axs = plt.subplots(fig_rows, fig_cols, figsize = [20, 20])\n\n    for idx, img in enumerate(range(start_stop, plot_range, step_size)):\n        axs.flat[idx].imshow(ndi.rotate(brain_vol_data[img, :, :], 90))\n        print(img)\n        axs.flat[idx].axis('off')\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset for Linear regressor, KNN and decision tree","metadata":{}},{"cell_type":"code","source":"# data \nX = input_d\ny = gt\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n\nX_train_copy = X_train.copy()\nX_test_copy = X_test.copy()\n \n# Fit the standardization scaler onto the training data\nstandard = StandardScaler().fit(X_train_copy)\n \n# Transform the training data\nX_train_stan = standard.transform(X_train_copy)\nX_test_stan = standard.transform(X_test_copy)\n\nX_train_tensor = torch.tensor(X_train_stan, dtype=torch.float32)\nX_test_tensor = torch.tensor(X_test_stan, dtype=torch.float32)\n\ny_train_tensor = torch.tensor(y_train, dtype=torch.float32)\ny_test_tensor = torch.tensor(y_test, dtype=torch.float32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Regressor Model","metadata":{}},{"cell_type":"code","source":"# Define the model and loss functions\nclass LinearRegressor(nn.Module):\n  def __init__(self):\n    super(LinearRegressor, self).__init__()\n    self.fc1 = nn.Linear(9, 1)  # Input layer with 9 features and 1 output\n\n  def forward(self, x):\n    x = self.fc1(x)\n    return x\n\nmse_loss = nn.MSELoss()\n\ndef median_squared_error(y_true, y_pred):\n  squared_errors = F.mse_loss(y_true, y_pred, reduction = 'none')\n  median_error = torch.median(squared_errors)\n  return median_error\n\ndef combined_loss(y_true, y_pred, weight_mse = 0.5, weight_median = 0.5):\n  mse = mse_loss(y_true, y_pred)\n  median_error = median_squared_error(y_true, y_pred)\n  return weight_mse * mse + weight_median * median_error","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training loop\ndef train(model, optimizer, data_loader, target_loader, epochs = 10):\n    losses = []\n    for epoch in range(epochs):\n        for data, target in zip(data_loader, target_loader):  # Iterate through batches in the dataloader\n            optimizer.zero_grad()  # Clear gradients before each pass\n#             print(data, target)\n            y_pred = model(data)  # Forward pass\n            loss = combined_loss(target, y_pred)  # Calculate combined loss\n            loss.backward()  # Backpropagation\n            optimizer.step()  # Update model weights\n\n#       Print training losses\n        losses.append(loss.item())\n        print(f\"Epoch: {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n    plt.plot(range(0, epochs), losses)\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training data (Fv, GT)\ntrain_dataset = (X_train_tensor, y_train)\ntrain_loader = DataLoader(train_dataset, batch_size = 1, shuffle = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LinearRegressor()\n# summary(model, (1, 9))\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n\n# Train the model\ntrain(model, optimizer, X_train_tensor, y_train_tensor, epochs = 100) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### KNN and Decision Tree classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# KNN classifier\nknn = KNeighborsClassifier(n_neighbors = 3) \nknn.fit(X_train, y_train)\ny_pred_knn = knn.predict(X_test)\n\n# Decision tree classifier\ndtree = DecisionTreeClassifier()\ndtree.fit(X_train, y_train)\ny_pred_dtree = dtree.predict(X_test)\n\n# Evaluate model performance (assuming regression target)\nmse_knn = mean_squared_error(y_test, y_pred_knn)\nmse_dtree = mean_squared_error(y_test, y_pred_dtree)\n\nprint(f\"KNN MSE: {mse_knn:.4f} days\")\nprint(f\"Decision Tree MSE: {mse_dtree:.4f} days\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}